I think a ridgeline plot could be really cool... see this website on how to make one: https://r-graph-gallery.com/294-basic-ridgeline-plot.html
I got some ideas from the website "from data to viz"

For the map, I think it would be really cool to show a density plot of the total scores for that site
this would be density on the y axis and score 1-5 on the x axis 
here's a website on how to make a density plot:
https://r-graph-gallery.com/21-distribution-plot-using-ggplot2.html

Load libraries 
```{r}
library(ggplot2)
library(ggridges) 
library(googledrive) 
library(googlesheets4) 
library(dplyr)
library(tidyverse)
library(radiant.data)
```


Read in the data 
```{r}
url <- "https://docs.google.com/spreadsheets/d/1cUz4WZ1CRHFicuVUt82kJ_mL9Ur861Dn1c0BYu3NmRY/edit#gid=0"

MPS_tracker_data <- read_sheet(url)
```

Practice making a ridgeline plot with the diamonds dataset 
```{r}
ggplot(diamonds, aes(x = price, y = cut, fill = cut)) +
  geom_density_ridges() +
  theme_ridges() + 
  theme(legend.position = "none")
```

Now let's try that with our data 
```{r}
# let's try to put the country on the y axis and the average score on the x axis 

# make a mini data frame of what we want 
# we have the problem that if we are to compare TOTAL scores accross countries, some countries have more sites and observations... this is why I'm going with the average for now
# ACTUALLY uh oh... you can't do this type of plot with the grouped averages 

# # this object is useless right now: 
# country_total_scores <- MPS_tracker_data |> 
#   mutate(as.factor(country)) |> 
#   group_by(country) |> 
#   summarise(sum_score = mean(as.numeric(score), na.rm = TRUE), na.rm = TRUE) |> 
#   na.omit() # how do I get rid of NAs?

# take out all rows that have "don't know or NA"
country_scores_no_na <- MPS_tracker_data[!(MPS_tracker_data$score == "Don't know or N/A"), ] |> 
  na.omit() |> 
  select(country, score)

  
ggplot(country_scores_no_na, aes(x = score, y = country, fill = country)) +
  geom_density_ridges(scale = 1.2) +
  theme_ridges() 
```

```{r}
# another tester one: 
# library
library(ggridges)
library(ggplot2)
library(viridis)
library(hrbrthemes)

# Plot
ggplot(lincoln_weather, aes(x = `Mean Temperature [F]`, y = `Month`, fill = ..x..)) +
  geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01) +
  scale_fill_viridis(name = "Temp. [F]", option = "C") +
  labs(title = 'Temperatures in Lincoln NE in 2016') +
  theme_ipsum() +
    theme(
      legend.position="none",
      panel.spacing = unit(0.1, "lines"),
      strip.text.x = element_text(size = 8)
    )
```

Try making a density plot comparing two things with transparency
```{r}
# compare surveillance and enforcement scores across all sites in 2022
# by the way I think I deleted "MPS_no_na" somehow so you'll have to recreate it later
MPS_no_na <- MPS_tracker_data |> na.omit()

surveillance_df <- MPS_tracker_data |> 
  filter(category == "Surveilance and Enforcement", 
         site == c("Bahamas EEZ", 
                   "Celestun Fishery Refuge", 
                   "Costa del Ecuador", 
                   "National Parcs", 
                   "PAN", 
                   "Scorpion Reef National Park (Arrecife Alacrane Bioshpere Reserve)"))

  

ggplot(data = surveillance_df, 
       aes(x = score, group = site, fill = site)) + 
  geom_density(adjust = 1.5, alpha = 0.5) + 
  theme(legend.position = "bottom") + 
  theme_ipsum() + 
  labs(title = "Density of surveillance and enforcement scores across five sites")
```

# I have an idea! compare certain aspects of the enforcement strategy with the END GOAL. There are a couple end goals that we could go for: 
- decreased bicatch (8 observations)
- community benefits (8 observations)
- decreased protected hunting (8 observations)
- declining infractions (8 observations) 
- marine population status (8 observations)
possibly more! 

a useful question to ask could be something like: how does community involvement affect decreased bicatch... haha that could be interesting to understand! BUT we would need a different type of dataset for this... I don't even think that this dataset is tidy yet!! we need to have a single row for an entire year at a certain site... how can we do this? pivot _wide() ??
obviously there is not much data for making specific inferences yet, but this program provides a framework to eventually do that... and we should brag about the fact that this is the first tool to track and monitor the marine enforcement efforts. This is why this is so important... say stuff like this in the next presentation!! 


create pivot wide dataframe where each row is a years worth of data 
```{r}
# create unique id column for each annual site entry (called "id")
MPS_tracker_data$id <- paste(MPS_tracker_data$year, MPS_tracker_data$site, sep = "_")

MPS_wide <- MPS_tracker_data |> 
  pivot_wider(id_cols = id, 
              names_from = sub_category, 
              values_from = score) |> 
  janitor::clean_names()

# where are all these null values coming from??
null_explore <- MPS_tracker_data |> 
  filter(score == "NULL") # ----- welp not from here! there are no values that say "NULL"

# from looking at the wide data structure it looks like there are duplicate rows with different score values... some two some 3??
# --- one row that has this is 2020_Bahamas EEZ ... (2 for the sanctions and prosecutions) let's take a look at it 
bahamas_eez_2020 <- 
  MPS_tracker_data |> filter(id == "2020_Bahamas EEZ", 
                             sub_category == "Sanctions & Prosecutions")



```

how many duplicate rows do we have 
```{r}
print(duplicated(MPS_tracker_data)) # welp it looks like there are now duplicate rows... so why are there some multiple values in our wide data frame ??
```

Explore data w `dtab()` 
```{r}
dtab(MPS_tracker_data)
```

Cases where there are duplicate scores for some reason: 
- 2020 bahamas eez has two entries for sanctions and prosecutions 
- many more 

First let's try making a corrplot with all these variables: 
```{r}
library(corrplot)
#MPS_wide_num <- as.numeric(MPS_wide)
# i think that cor requires matrix format 
MPS_wide_matrix <- data.matrix(MPS_wide, rownames.force = NA)
MPS_cor <- cor(MPS_wide_matrix, use = "complete.obs")

corrplot(MPS_cor, method = "number")

# check class of values 
class(MPS_wide[5,20])
library(Hmisc)
all_cor <- rcorr(MPS_wide_matrix)
#all_cor # running this will give a very large output so it's commented out here 
#BUT we found some interesting correlations!! Let's see if we can test the significance 


```

```{r}
# try the function unnest(): 
MPS_unnest <- unnest(MPS_wide, cols = c(international_institutional_collaboration))
MPS_unnest <- unnest(MPS_unnest, cols = c(national_institutional_collaboration))
MPS_unnest <- unnest(MPS_unnest, cols = c(staff_numbers))
MPS_unnest <- unnest(MPS_unnest, cols = c(vessel_availability))
MPS_unnest <- unnest(MPS_unnest, cols = c(community_benefits))
MPS_unnest <- unnest(MPS_unnest, cols = c(sanctions_prosecutions))
MPS_unnest <- unnest(MPS_unnest, cols = c(standard_operating_procedures))
MPS_unnest <- unnest(MPS_unnest, cols = c(fishing_sector_collaboration))
MPS_unnest <- unnest(MPS_unnest, cols = c(funding))

# WARNING: THIS changed UP THE DATA.. PROBABLY SHOULDN'T USE IT NOT SURE WHAT I JUST DID 
# JUST FOR FUN LET'S SEE IF WE CAN MAKE A SCATTERPLOT WITH IT 

# don't work m8
# ggplot(data = MPS_unnest, aes(x = funding, y = decreased_protected_hunting)) + geom_point()



# national_institutional_collaboration,
                                        # staff_numbers,
                                        # vessel_availability,
                                        # community_benefits,
                                        # sanctions_prosecutions,
                                        # standard_operating_procedures,
                                        # fishing_sector_collaboration,
                                        # funding

# --- ok let's try a different way I found online:
#MPS_unnest <- setNames(with(MPS_wide, data.frame(rep(id,lengths(staff_numbers)),unlist(staff_numbers))),names(MPS_wide))

```
### Scatter Plot 
Let's plot some of the things that are correlated with each other to see if we can justify putting scatter plot functionality into the shiny app 
```{r}
## see if these correlations are actually significant
cor.test(MPS_wide$decreased_protected_hunting, MPS_wide$surveillance_prioritization)
# = significant 
cor.test(MPS_wide$declining_infractions, MPS_wide$surveillance_prioritization)
# = significant
cor.test(MPS_wide$marine_population_status, MPS_wide$surveillance_prioritization)
# = significant
cor.test(MPS_wide$sighting_to_apprehension, MPS_wide$decreased_bycatch)
# = significant
cor.test(MPS_wide$decreased_protected_hunting, MPS_wide$surveillance_prioritization)
# = 
cor.test(MPS_wide$decreased_protected_hunting, MPS_wide$surveillance_prioritization)
# =
cor.test(MPS_wide$decreased_protected_hunting, MPS_wide$surveillance_prioritization)
# = 
cor.test(MPS_wide$decreased_protected_hunting, MPS_wide$surveillance_prioritization)
# = 
```




try making a scatter plot with regression line for some variable comparisons: 
```{r}
# ggplot(data = MPS_wide, 
#        aes(x = vessel))
```

Line graph over time:
```{r}
dat_1 <- MPS_tracker_data |> 
  filter(str_detect(site, "Galapagos"), 
         sub_category == "Funding") |> 
  na.omit() 

ggplot(data = dat_1, 
       mapping = aes(x = year, y = score, group = 1)) + 
  geom_line() + 
  geom_point() + 
  labs(title = "Funding at Galapagos protected site")
```


Example of circular bar chart: 
```{r}
# Create dataset
data <- data.frame(
  individual=paste( "Mister ", seq(1,60), sep=""),
  value=sample( seq(10,100), 60, replace=T)
)
 
# Set a number of 'empty bar'
empty_bar <- 10
 
# Add lines to the initial dataset
to_add <- matrix(NA, empty_bar, ncol(data))
colnames(to_add) <- colnames(data)
data <- rbind(data, to_add)
data$id <- seq(1, nrow(data))
 
# Get the name and the y position of each label
label_data <- data
number_of_bar <- nrow(label_data)
angle <- 90 - 360 * (label_data$id-0.5) /number_of_bar     # I substract 0.5 because the letter must have the angle of the center of the bars. Not extreme right(1) or extreme left (0)
label_data$hjust <- ifelse( angle < -90, 1, 0)
label_data$angle <- ifelse(angle < -90, angle+180, angle)
 
# Make the plot
p_ex <- ggplot(data, aes(x=as.factor(id), y=value)) +       # Note that id is a factor. If x is numeric, there is some space between the first bar
  geom_bar(stat="identity", fill=alpha("green", 0.3)) +
  ylim(-100,120) +
  theme_minimal() +
  theme(
    axis.text = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    plot.margin = unit(rep(-1,4), "cm") 
  ) +
  coord_polar(start = 0) + 
  geom_text(data=label_data, aes(x=id, y=value+10, label=individual, hjust=hjust), color="black", fontface="bold",alpha=0.6, size=2.5, angle= label_data$angle, inherit.aes = FALSE ) 
 
p_ex
```


Ok now here's a version with space between groups: 
```{r}
# library
library(tidyverse)
 
# Create dataset
data <- data.frame(
  individual=paste( "Mister ", seq(1,60), sep=""),
  group=c( rep('A', 10), rep('B', 30), rep('C', 14), rep('D', 6)) ,
  value=sample( seq(10,100), 60, replace=T)
)

# arrange the values so it becomes ordered: 
data = data %>% arrange(group, value)
 
# Set a number of 'empty bar' to add at the end of each group
empty_bar <- 4
to_add <- data.frame( matrix(NA, empty_bar*nlevels(data$group), ncol(data)) )
colnames(to_add) <- colnames(data)
to_add$group <- rep(levels(data$group), each=empty_bar)
data <- rbind(data, to_add)
data <- data %>% arrange(group)
data$id <- seq(1, nrow(data))
 
# Get the name and the y position of each label
label_data <- data
number_of_bar <- nrow(label_data)
angle <- 90 - 360 * (label_data$id-0.5) /number_of_bar     # I substract 0.5 because the letter must have the angle of the center of the bars. Not extreme right(1) or extreme left (0)
label_data$hjust <- ifelse( angle < -90, 1, 0)
label_data$angle <- ifelse(angle < -90, angle+180, angle)
 
# Make the plot
p_ex2 <- ggplot(data, aes(x=as.factor(id), y=value, fill=group)) +       # Note that id is a factor. If x is numeric, there is some space between the first bar
  geom_bar(stat="identity", alpha=0.5) +
  ylim(-100,120) +
  theme_minimal() +
  theme(
    legend.position = "none",
    axis.text = element_blank(),
    axis.title = element_blank(),
    panel.grid = element_blank(),
    plot.margin = unit(rep(-1,4), "cm") 
  ) +
  coord_polar() + 
  geom_text(data=label_data, aes(x=id, y=value+10, label=individual, hjust=hjust), color="black", fontface="bold",alpha=0.6, size=2.5, angle= label_data$angle, inherit.aes = FALSE ) 
 
p_ex2
```



Let's Try with our data! 
```{r}
# let's pick on site for this: '2020_Bahamas EEZ'... we'll filter for it
baham20 <- MPS_tracker_data |> 
  filter(site == "Bahamas EEZ", 
         year == "2020")
baham20 <- baham20 |> arrange(category) 
baham20 <- baham20 |> arrange(category, score) # for some reason this is creating output
# ok I think now it's in the format that we want 
# set up angle for text 
# Get the name and the y position of each label
number_of_bar <- nrow(baham20)
baham20$id_num <- seq(1, nrow(baham20))
angle <- 90 - 360 * (baham20$id_num-0.5) /number_of_bar     # I substract 0.5 because the letter must have the angle of the center of the bars. Not extreme right(1) or extreme left (0)
baham20$hjust <- ifelse( angle < -90, 1, 0)
baham20$angle <- ifelse(angle < -90, angle+180, angle)


# Make the plot
p <- ggplot(data = baham20, aes(x = as.factor(id_num), y= score, fill=category)) +       # Note that id is a factor. If x is numeric, there is some space between the first bar
  geom_bar(stat = "identity") +
  ylim(-2,10) +
  theme_minimal() +
   theme(
     axis.text = element_blank(),
     axis.title = element_blank(),
     panel.grid = element_blank(),
     #plot.margin = unit(rep(-1,4), "cm") 
   ) +
  coord_polar(start = 0) + 
  
  geom_text(data = baham20, aes(x=id_num, y=score + 1, label=sub_category, hjust=hjust), color="black", fontface="bold", alpha=.8, size=2.2, angle= baham20$angle, inherit.aes = FALSE ) +
  
  labs(title = "Bahamas EEZ scores in 2020") 


p

### IDEA: COULD WRAP THIS IN SOME PLOTLY THING SO THE USER CAN HOVER OVER A BAR SEGMENT AND IT WILL DISPLAY THE SCORE!!!!! WOOOOOOO 
```



Try making a lollipop plot to show a years worth of category scores for a certain site

example from online: 
```{r}
# Create data (could be way easier but it's late)
value1 <- abs(rnorm(6))*2
don <- data.frame(
  x=LETTERS[1:24], 
  val=c( value1, value1+1+rnorm(6, 14,1) ,value1+1+rnorm(6, sd=1) ,value1+1+rnorm(6, 12, 1) ),
  grp=rep(c("grp1", "grp2", "grp3", "grp4"), each=6)
  ) %>%
  arrange(val) %>%
  mutate(x=factor(x, x))


# With a bit more style
ggplot(don) +
  geom_segment( aes(x=x, xend=x, y=0, yend=val), color="grey") +
  geom_point( aes(x=x, y=val, color=grp), size=3 ) +
  coord_flip()+
  theme_ipsum() +
  theme(
    legend.position = "none",
    panel.border = element_blank(),
    panel.spacing = unit(0.1, "lines"),
    strip.text.x = element_text(size = 8)
  ) +
  xlab("") +
  ylab("Value of Y") +
  facet_wrap(~grp, ncol=1, scale="free_y")
```

Ok now let's try it with our data: 
```{r}
# filter down to four or so sites that the user would like to compare category scores to each other 
#---- hopefully the user can also select year of certain sites to compare against eachother??

# let's use data from 2020 and bahamas eez, costa del ecuador, galapagos marine reserve, and national parcs
# something weird is happening where I'm losing data 
# title = comaring sites in ecuador 
# filtering to the first 4 I see..
lollidat <- MPS_tracker_data |> 
  filter(year == "2022", 
         country == "Ecuador")
sub1 <- lollidat |> 
  filter(site == "Reserva EcolÃ³gica Manglares Churute") |> 
  group_by(category) |> 
  summarise(score = mean(score, na.rm = TRUE), 
            site = site)
sub2 <- lollidat |> 
  filter(site == "Galapagos Marine Reserve") |> 
  group_by(category) |> 
  summarise(score = mean(score, na.rm = TRUE), 
            site = site)
sub3 <- lollidat |> 
  filter(site == "Parque Nacional Machalilla") |> 
  group_by(category) |> 
  summarise(score = mean(score, na.rm = TRUE), 
            site = site)
sub4 <- lollidat |> 
  filter(site == "Refugio de Vida Silvestre Manglares El Morro") |> 
  group_by(category) |> 
  summarise(score = mean(score, na.rm = TRUE), 
            site = site)
lolli_cat_score <- bind_rows(sub1, sub2, sub3, sub4)

         
# make our grouped lollipop plot
ggplot(lolli_cat_score) +
  geom_segment( aes(x=category, xend=category, y=0, yend=score), color="grey") +
  geom_point( aes(x=category, y=score, color=site), size=3 ) +
  coord_flip()+
  theme_ipsum() +
  theme(
    legend.position = "none",
    panel.border = element_blank(),
    panel.spacing = unit(0.1, "lines"),
    strip.text.x = element_text(size = 8), 
    axis.text.y = element_text(size = 7), 
    plot.title = element_text(size = 12)
  ) +
  labs(title = "Comparing Four Sites in Ecuador in 2022", size = 1) +
  xlab("Scoring Category") +
  ylab("Score") +
  facet_wrap(~site, ncol=1, scale="free_y")
```



This is a sample version that is highly customized to show the mean changing over time as well as vertain scores... not sure if it will be able to show our scores too easily 
https://r-graph-gallery.com/web-lollipop-plot-with-R-the-office.html


UP NEXT: SUNBURST AND LOLLIPOP